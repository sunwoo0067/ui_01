#!/usr/bin/env python3
"""
ë„ë§¤ê¾¹/ë„ë§¤ë§¤ ìƒí’ˆë²ˆí˜¸ ê¸°ë°˜ ë°°ì¹˜ ìˆ˜ì§‘
getItemView + multiple=trueë¡œ 100ê°œì”© ìˆ˜ì§‘
"""

import asyncio
import json
import requests
import hashlib
from datetime import datetime
from loguru import logger
from src.services.database_service import DatabaseService


class ItemNumberBatchCollector:
    """ìƒí’ˆë²ˆí˜¸ ê¸°ë°˜ ë°°ì¹˜ ìˆ˜ì§‘ê¸°"""
    
    def __init__(self):
        self.db = DatabaseService()
        self.api_key = None
        self.version = "4.1"
        self.url = 'https://domeggook.com/ssl/api/'
        
        self.supplier_ids = {
            "dome": "d9e6fa42-9bd4-438f-bf3b-10cf199eabd2",
            "supply": "a9990a09-ae6f-474b-87b8-75840a110519"
        }
    
    async def _init_credentials(self):
        """ì¸ì¦ ì •ë³´ ì´ˆê¸°í™”"""
        accounts = await self.db.select_data(
            'supplier_accounts',
            {'supplier_id': 'baa2ccd3-a328-4387-b307-6ae89aea331b'}
        )
        
        if accounts:
            credentials = json.loads(accounts[0]['account_credentials'])
            self.api_key = credentials.get('api_key')
            self.version = credentials.get('version', '4.1')
    
    def collect_batch_by_numbers(self, start_no: int, end_no: int, batch_size: int = 100):
        """ìƒí’ˆë²ˆí˜¸ ë²”ìœ„ë¡œ ë°°ì¹˜ ìˆ˜ì§‘ (getItemView multiple)"""
        
        all_products = []
        
        current = start_no
        while current <= end_no:
            # 100ê°œì”© ìƒí’ˆë²ˆí˜¸ ìƒì„±
            numbers = []
            for i in range(batch_size):
                if current + i > end_no:
                    break
                numbers.append(str(current + i))
            
            if not numbers:
                break
            
            # ì½¤ë§ˆë¡œ ì—°ê²°
            no_param = ','.join(numbers)
            
            param = {
                'ver': self.version,
                'mode': 'getItemView',
                'aid': self.api_key,
                'no': no_param,
                'multiple': 'true',
                'om': 'json'
            }
            
            try:
                res = requests.get(self.url, params=param, timeout=30)
                
                if res.status_code == 200:
                    data = json.loads(res.content)
                    
                    # ì—ëŸ¬ ì²´í¬
                    if 'errors' in data:
                        logger.warning(f"   ë²”ìœ„ {current}-{current+len(numbers)-1}: ì—ëŸ¬")
                        current += batch_size
                        continue
                    
                    # ìƒí’ˆ ë°ì´í„° ì¶”ì¶œ
                    items_data = data.get('domeggook', {}).get('items', [])
                    
                    if items_data:
                        if not isinstance(items_data, list):
                            items_data = [items_data]
                        
                        all_products.extend(items_data)
                        logger.info(f"   ë²”ìœ„ {current}-{current+len(numbers)-1}: +{len(items_data)}ê°œ (ëˆ„ì : {len(all_products)})")
                    else:
                        logger.debug(f"   ë²”ìœ„ {current}-{current+len(numbers)-1}: 0ê°œ")
                
                current += batch_size
                
            except Exception as e:
                logger.error(f"   ì˜¤ë¥˜: {e}")
                current += batch_size
                continue
        
        return all_products
    
    async def collect_simple_keyword(self, market: str, keyword: str = "ê°€ë°©", target: int = 5000):
        """ê°„ë‹¨í•œ í‚¤ì›Œë“œë¡œ ë°°ì¹˜ ìˆ˜ì§‘ (sz=200)"""
        market_name = "ë„ë§¤ê¾¹" if market == "dome" else "ë„ë§¤ë§¤"
        
        logger.info("="*70)
        logger.info(f"ğŸ” {market_name} í‚¤ì›Œë“œ ê¸°ë°˜ ë°°ì¹˜ ìˆ˜ì§‘")
        logger.info(f"   í‚¤ì›Œë“œ: '{keyword}'")
        logger.info(f"   ëª©í‘œ: {target:,}ê°œ")
        logger.info("="*70)
        
        all_products = []
        page = 1
        max_pages = (target // 200) + 1
        
        while len(all_products) < target and page <= max_pages:
            param = {
                'ver': self.version,
                'mode': 'getItemList',
                'aid': self.api_key,
                'market': market,
                'om': 'json',
                'sz': 200,
                'pg': page,
                'kw': keyword,
                'so': 'rd'  # ë„ë§¤ê¾¹ë­í‚¹ìˆœ
            }
            
            try:
                res = requests.get(self.url, params=param, timeout=30)
                
                if res.status_code == 200:
                    data = json.loads(res.content)
                    
                    if 'errors' in data:
                        logger.error(f"API ì—ëŸ¬: {data['errors'].get('message')}")
                        break
                    
                    header = data.get('domeggook', {}).get('header', {})
                    total_items = header.get('numberOfItems', 0)
                    
                    if page == 1:
                        logger.info(f"\nğŸ“Š ê²€ìƒ‰ ê²°ê³¼: {total_items:,}ê°œ")
                        if total_items == 0:
                            logger.warning(f"í‚¤ì›Œë“œ '{keyword}'ë¡œ ìƒí’ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                            return []
                    
                    items = data.get('domeggook', {}).get('list', {}).get('item', [])
                    
                    if not items:
                        break
                    
                    if isinstance(items, dict):
                        items = [items]
                    
                    # ìƒí’ˆ ì •ë³´ ì¶”ì¶œ
                    for item in items:
                        product = {
                            "supplier_key": str(item.get("no", "")),
                            "title": item.get("title", ""),
                            "price": int(item.get("price", 0)),
                            "unit_quantity": int(item.get("unitQty", 1)),
                            "seller_id": item.get("id", ""),
                            "seller_nick": item.get("nick", ""),
                            "thumbnail_url": item.get("thumb", ""),
                            "product_url": item.get("url", ""),
                            "company_only": item.get("comOnly") == "true",
                            "adult_only": item.get("adultOnly") == "true",
                            "lowest_price": item.get("lwp") == "true",
                            "use_options": item.get("useopt") == "true",
                            "market_info": item.get("market", {}),
                            "dome_price": item.get("domePrice", ""),
                            "quantity_info": item.get("qty", {}),
                            "delivery_info": item.get("deli", {}),
                            "idx_com": item.get("idxCOM", ""),
                            "market": market,
                            "market_name": market_name,
                            "search_keyword": keyword,
                            "collected_at": datetime.now().isoformat()
                        }
                        
                        all_products.append(product)
                    
                    logger.info(f"   í˜ì´ì§€ {page}: +{len(items)}ê°œ (ëˆ„ì : {len(all_products)}/{total_items})")
                    
                    if len(all_products) >= total_items or len(all_products) >= target:
                        break
                    
                    page += 1
                    
                else:
                    logger.error(f"API ì˜¤ë¥˜: {res.status_code}")
                    break
                    
            except Exception as e:
                logger.error(f"ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
                break
        
        logger.info(f"\nâœ… ìˆ˜ì§‘ ì™„ë£Œ: {len(all_products)}ê°œ")
        
        # ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥
        supplier_id = self.supplier_ids[market]
        saved = await self._save_to_db(all_products, supplier_id, market)
        
        logger.info(f"ğŸ’¾ ì €ì¥ ì™„ë£Œ: {saved}ê°œ")
        
        return {
            "market": market_name,
            "keyword": keyword,
            "total": len(all_products),
            "saved": saved
        }
    
    async def _save_to_db(self, products, supplier_id, market):
        """ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥"""
        saved = 0
        
        for product in products:
            try:
                supplier_product_id = f"{market}_{product.get('supplier_key', '')}"
                
                data_str = json.dumps(product, sort_keys=True, ensure_ascii=False)
                data_hash = hashlib.md5(data_str.encode('utf-8')).hexdigest()
                
                raw_data = {
                    "supplier_id": supplier_id,
                    "raw_data": json.dumps(product, ensure_ascii=False),
                    "collection_method": "api",
                    "collection_source": "keyword_batch",
                    "supplier_product_id": supplier_product_id,
                    "is_processed": False,
                    "data_hash": data_hash,
                    "metadata": json.dumps({
                        "collected_at": product.get("collected_at"),
                        "keyword": product.get("search_keyword")
                    }, ensure_ascii=False)
                }
                
                existing = await self.db.select_data(
                    "raw_product_data",
                    {"supplier_id": supplier_id, "supplier_product_id": supplier_product_id}
                )
                
                if existing:
                    await self.db.update_data("raw_product_data", raw_data, {"id": existing[0]["id"]})
                else:
                    await self.db.insert_data("raw_product_data", raw_data)
                
                saved += 1
                
            except Exception as e:
                logger.warning(f"ì €ì¥ ì‹¤íŒ¨: {e}")
                continue
        
        return saved


async def main():
    """ë©”ì¸ ì‹¤í–‰"""
    collector = ItemNumberBatchCollector()
    await collector._init_credentials()
    
    logger.info("ğŸ¯ ë„ë§¤ê¾¹/ë„ë§¤ë§¤ ë°°ì¹˜ íƒ€ì… ìˆ˜ì§‘")
    logger.info("   ë°©ì‹: í‚¤ì›Œë“œ ê¸°ë°˜ (sz=200ê°œì”©)\n")
    
    # ë‹¤ì–‘í•œ í‚¤ì›Œë“œë¡œ ìˆ˜ì§‘ (ì¤‘ë³µ ì œê±°ë¨)
    keywords = [
        ("ê°€ë°©", 5000),
        ("ì˜ë¥˜", 5000),
        ("í™”ì¥í’ˆ", 3000),
        ("ìƒí™œìš©í’ˆ", 3000),
        ("ì£¼ë°©ìš©í’ˆ", 2000),
        ("ì „ìì œí’ˆ", 2000),
        ("ë¬¸êµ¬", 2000),
        ("ì™„êµ¬", 2000),
        ("ìŠ¤í¬ì¸ ", 2000),
        ("ì‹í’ˆ", 2000)
    ]
    
    results = {}
    
    # ë„ë§¤ê¾¹
    logger.info("\n" + "="*70)
    logger.info("1ë‹¨ê³„: ë„ë§¤ê¾¹(dome) ìˆ˜ì§‘")
    logger.info("="*70)
    
    dome_total = 0
    for keyword, target in keywords:
        result = await collector.collect_simple_keyword("dome", keyword, target)
        dome_total += result['total']
        logger.info(f"\n   '{keyword}': {result['total']:,}ê°œ ìˆ˜ì§‘, {result['saved']:,}ê°œ ì €ì¥")
    
    results['dome'] = {"total": dome_total}
    
    # ë„ë§¤ë§¤
    logger.info("\n" + "="*70)
    logger.info("2ë‹¨ê³„: ë„ë§¤ë§¤(supply) ìˆ˜ì§‘")
    logger.info("="*70)
    
    supply_total = 0
    for keyword, target in keywords:
        result = await collector.collect_simple_keyword("supply", keyword, target)
        supply_total += result['total']
        logger.info(f"\n   '{keyword}': {result['total']:,}ê°œ ìˆ˜ì§‘, {result['saved']:,}ê°œ ì €ì¥")
    
    results['supply'] = {"total": supply_total}
    
    # ìµœì¢… ê²°ê³¼
    logger.info("\n" + "="*70)
    logger.info("âœ… ë°°ì¹˜ ìˆ˜ì§‘ ì™„ë£Œ")
    logger.info("="*70)
    logger.info(f"   ë„ë§¤ê¾¹(dome): {dome_total:,}ê°œ")
    logger.info(f"   ë„ë§¤ë§¤(supply): {supply_total:,}ê°œ")
    logger.info(f"   ì´ê³„: {dome_total + supply_total:,}ê°œ")
    logger.info("="*70)
    
    with open('domaemae_keyword_batch_results.json', 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)


if __name__ == "__main__":
    asyncio.run(main())

