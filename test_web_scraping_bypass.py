"""
í”„ë¡ì‹œ ê´€ë¦¬ ë° ì›¹ ìŠ¤í¬ë˜í•‘ ìš°íšŒ í…ŒìŠ¤íŠ¸
"""

import asyncio
import json
from datetime import datetime, timezone
from loguru import logger

from src.services.advanced_web_scraper import AdvancedWebScraper, ProxyScraper
from src.services.coupang_search_service import CoupangSearchService
from src.services.naver_smartstore_search_service import NaverSmartStoreSearchService


class WebScrapingBypassTester:
    """ì›¹ ìŠ¤í¬ë˜í•‘ ìš°íšŒ í…ŒìŠ¤íŠ¸ í´ë˜ìŠ¤"""

    def __init__(self):
        self.scraper = AdvancedWebScraper()
        self.proxy_scraper = ProxyScraper()
        self.coupang_service = CoupangSearchService()
        self.naver_service = NaverSmartStoreSearchService()

    async def test_proxy_collection(self) -> bool:
        """í”„ë¡ì‹œ ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸"""
        try:
            logger.info("\n=== í”„ë¡ì‹œ ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸ ì‹œì‘ ===")
            
            # ë¬´ë£Œ í”„ë¡ì‹œ ìˆ˜ì§‘
            proxies = await self.proxy_scraper.get_free_proxies()
            
            if proxies:
                logger.info(f"âœ… í”„ë¡ì‹œ ìˆ˜ì§‘ ì„±ê³µ: {len(proxies)}ê°œ")
                
                # í”„ë¡ì‹œ ìœ íš¨ì„± ê²€ì¦
                valid_proxies = await self.proxy_scraper.validate_proxies(proxies)
                
                if valid_proxies:
                    logger.info(f"âœ… ìœ íš¨í•œ í”„ë¡ì‹œ: {len(valid_proxies)}ê°œ")
                    
                    # ìƒìœ„ 5ê°œ í”„ë¡ì‹œë¥¼ ìŠ¤í¬ë˜í¼ì— ì¶”ê°€
                    for proxy in valid_proxies[:5]:
                        self.scraper.add_proxy(proxy)
                        logger.info(f"í”„ë¡ì‹œ ì¶”ê°€: {proxy}")
                    
                    return True
                else:
                    logger.warning("âš ï¸ ìœ íš¨í•œ í”„ë¡ì‹œ ì—†ìŒ")
                    return False
            else:
                logger.error("âŒ í”„ë¡ì‹œ ìˆ˜ì§‘ ì‹¤íŒ¨")
                return False
                
        except Exception as e:
            logger.error(f"âŒ í”„ë¡ì‹œ ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜: {e}")
            return False

    async def test_advanced_scraping(self) -> bool:
        """ê³ ê¸‰ ìŠ¤í¬ë˜í•‘ í…ŒìŠ¤íŠ¸"""
        try:
            logger.info("\n=== ê³ ê¸‰ ìŠ¤í¬ë˜í•‘ í…ŒìŠ¤íŠ¸ ì‹œì‘ ===")
            
            # í…ŒìŠ¤íŠ¸ URLë“¤
            test_urls = [
                "https://httpbin.org/user-agent",
                "https://httpbin.org/headers",
                "https://httpbin.org/ip",
            ]
            
            success_count = 0
            
            for url in test_urls:
                try:
                    logger.info(f"í…ŒìŠ¤íŠ¸ URL: {url}")
                    
                    # í˜ì´ì§€ ë‚´ìš© ê°€ì ¸ì˜¤ê¸°
                    content = await self.scraper.get_page_content(url)
                    
                    if content:
                        logger.info(f"âœ… {url} - ì„±ê³µ")
                        success_count += 1
                        
                        # JSON ì‘ë‹µì¸ ê²½ìš° íŒŒì‹±
                        if 'httpbin.org' in url:
                            try:
                                data = json.loads(content)
                                logger.info(f"  ì‘ë‹µ ë°ì´í„°: {data}")
                            except:
                                logger.info(f"  ì‘ë‹µ ë‚´ìš©: {content[:100]}...")
                    else:
                        logger.warning(f"âš ï¸ {url} - ì‹¤íŒ¨")
                        
                except Exception as e:
                    logger.error(f"âŒ {url} - ì˜¤ë¥˜: {e}")
                    continue
            
            logger.info(f"ê³ ê¸‰ ìŠ¤í¬ë˜í•‘ í…ŒìŠ¤íŠ¸ ê²°ê³¼: {success_count}/{len(test_urls)} ì„±ê³µ")
            return success_count > 0
            
        except Exception as e:
            logger.error(f"âŒ ê³ ê¸‰ ìŠ¤í¬ë˜í•‘ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜: {e}")
            return False

    async def test_coupang_bypass(self) -> bool:
        """ì¿ íŒ¡ ìš°íšŒ í…ŒìŠ¤íŠ¸"""
        try:
            logger.info("\n=== ì¿ íŒ¡ ìš°íšŒ í…ŒìŠ¤íŠ¸ ì‹œì‘ ===")
            
            # ì¿ íŒ¡ ìƒí’ˆ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
            products = await self.coupang_service.search_products(
                keyword="ë¬´ì„  ì´ì–´í°",
                page=1
            )
            
            if products:
                logger.info(f"âœ… ì¿ íŒ¡ ìš°íšŒ ì„±ê³µ: {len(products)}ê°œ ìƒí’ˆ")
                
                # ìƒí’ˆ ì •ë³´ ì¶œë ¥
                for i, product in enumerate(products[:3]):
                    logger.info(f"  {i+1}. {product.name}")
                    logger.info(f"     ê°€ê²©: {product.price:,}ì›")
                    logger.info(f"     íŒë§¤ì: {product.seller}")
                
                return True
            else:
                logger.warning("âš ï¸ ì¿ íŒ¡ ìš°íšŒ ì‹¤íŒ¨ - ìƒí’ˆ ì—†ìŒ")
                return False
                
        except Exception as e:
            logger.error(f"âŒ ì¿ íŒ¡ ìš°íšŒ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜: {e}")
            return False

    async def test_naver_bypass(self) -> bool:
        """ë„¤ì´ë²„ ìš°íšŒ í…ŒìŠ¤íŠ¸"""
        try:
            logger.info("\n=== ë„¤ì´ë²„ ìš°íšŒ í…ŒìŠ¤íŠ¸ ì‹œì‘ ===")
            
            # ë„¤ì´ë²„ ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ ìƒí’ˆ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
            products = await self.naver_service.search_products(
                keyword="ìŠ¤ë§ˆíŠ¸ì›Œì¹˜",
                page=1
            )
            
            if products:
                logger.info(f"âœ… ë„¤ì´ë²„ ìš°íšŒ ì„±ê³µ: {len(products)}ê°œ ìƒí’ˆ")
                
                # ìƒí’ˆ ì •ë³´ ì¶œë ¥
                for i, product in enumerate(products[:3]):
                    logger.info(f"  {i+1}. {product.name}")
                    logger.info(f"     ê°€ê²©: {product.price:,}ì›")
                    logger.info(f"     íŒë§¤ì: {product.seller}")
                
                return True
            else:
                logger.warning("âš ï¸ ë„¤ì´ë²„ ìš°íšŒ ì‹¤íŒ¨ - ìƒí’ˆ ì—†ìŒ")
                return False
                
        except Exception as e:
            logger.error(f"âŒ ë„¤ì´ë²„ ìš°íšŒ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜: {e}")
            return False

    async def test_rate_limit_handling(self) -> bool:
        """Rate Limit ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
        try:
            logger.info("\n=== Rate Limit ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ ì‹œì‘ ===")
            
            # ì—°ì† ìš”ì²­ìœ¼ë¡œ Rate Limit ìœ ë°œ ì‹œë„
            test_url = "https://httpbin.org/delay/1"
            
            success_count = 0
            total_requests = 5
            
            for i in range(total_requests):
                try:
                    logger.info(f"ìš”ì²­ {i+1}/{total_requests}")
                    
                    response = await self.scraper.make_request(test_url)
                    
                    if response:
                        logger.info(f"âœ… ìš”ì²­ {i+1} ì„±ê³µ")
                        success_count += 1
                    else:
                        logger.warning(f"âš ï¸ ìš”ì²­ {i+1} ì‹¤íŒ¨")
                        
                except Exception as e:
                    logger.error(f"âŒ ìš”ì²­ {i+1} ì˜¤ë¥˜: {e}")
                    continue
            
            logger.info(f"Rate Limit ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ ê²°ê³¼: {success_count}/{total_requests} ì„±ê³µ")
            return success_count > 0
            
        except Exception as e:
            logger.error(f"âŒ Rate Limit ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜: {e}")
            return False

    async def run_all_tests(self) -> bool:
        """ëª¨ë“  ìš°íšŒ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        try:
            logger.info("ğŸš€ ì›¹ ìŠ¤í¬ë˜í•‘ ìš°íšŒ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹œì‘")
            
            test_results = []
            
            # 1. í”„ë¡ì‹œ ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸
            test_results.append(await self.test_proxy_collection())
            
            # 2. ê³ ê¸‰ ìŠ¤í¬ë˜í•‘ í…ŒìŠ¤íŠ¸
            test_results.append(await self.test_advanced_scraping())
            
            # 3. ì¿ íŒ¡ ìš°íšŒ í…ŒìŠ¤íŠ¸
            test_results.append(await self.test_coupang_bypass())
            
            # 4. ë„¤ì´ë²„ ìš°íšŒ í…ŒìŠ¤íŠ¸
            test_results.append(await self.test_naver_bypass())
            
            # 5. Rate Limit ì²˜ë¦¬ í…ŒìŠ¤íŠ¸
            test_results.append(await self.test_rate_limit_handling())
            
            # ê²°ê³¼ ìš”ì•½
            passed_tests = sum(test_results)
            total_tests = len(test_results)
            
            logger.info(f"\nğŸ“Š ìš°íšŒ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½:")
            logger.info(f"  ì´ í…ŒìŠ¤íŠ¸: {total_tests}ê°œ")
            logger.info(f"  ì„±ê³µ: {passed_tests}ê°œ")
            logger.info(f"  ì‹¤íŒ¨: {total_tests - passed_tests}ê°œ")
            logger.info(f"  ì„±ê³µë¥ : {passed_tests/total_tests*100:.1f}%")
            
            if passed_tests == total_tests:
                logger.info("ğŸ‰ ëª¨ë“  ìš°íšŒ í…ŒìŠ¤íŠ¸ í†µê³¼!")
                return True
            else:
                logger.warning("âš ï¸ ì¼ë¶€ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
                return False
                
        except Exception as e:
            logger.error(f"âŒ ìš°íšŒ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
            return False


async def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    tester = WebScrapingBypassTester()
    success = await tester.run_all_tests()
    
    if success:
        logger.info("\nâœ… ì›¹ ìŠ¤í¬ë˜í•‘ ìš°íšŒ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    else:
        logger.error("\nâŒ ì›¹ ìŠ¤í¬ë˜í•‘ ìš°íšŒ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")


if __name__ == "__main__":
    asyncio.run(main())
