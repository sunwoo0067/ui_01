#!/usr/bin/env python3
"""
ì •ê·œí™”ëœ ìƒí’ˆ ë°ì´í„° ê¸°ë°˜ ëŒ€ëŸ‰ ê²½ìŸì‚¬ ë°ì´í„° ìˆ˜ì§‘
67,535ê°œ ìƒí’ˆì˜ ì¹´í…Œê³ ë¦¬ë³„ ê²½ìŸì‚¬ ê°€ê²© ë¶„ì„
"""

import asyncio
import json
from datetime import datetime
from typing import List, Dict, Set
from loguru import logger

from src.services.database_service import DatabaseService
from src.services.coupang_search_service import CoupangSearchService
from src.services.naver_smartstore_search_service import NaverSmartStoreSearchService
from src.services.price_comparison_service import PriceComparisonService


async def bulk_collect_competitor_data(
    limit: int = None,
    categories: List[str] = None,
    batch_size: int = 100
):
    """ëŒ€ëŸ‰ ê²½ìŸì‚¬ ë°ì´í„° ìˆ˜ì§‘"""
    
    db = DatabaseService()
    coupang_service = CoupangSearchService()
    naver_service = NaverSmartStoreSearchService()
    price_comparison_service = PriceComparisonService()
    
    logger.info("="*70)
    logger.info("ðŸ” ëŒ€ëŸ‰ ê²½ìŸì‚¬ ë°ì´í„° ìˆ˜ì§‘ ì‹œìž‘")
    logger.info(f"   ëŒ€ìƒ: ì •ê·œí™” ìƒí’ˆ (ì˜¤ë„ˆí´ëžœ)")
    logger.info(f"   ì œí•œ: {limit if limit else 'ì „ì²´'}")
    logger.info("="*70)
    
    start_time = datetime.now()
    
    # 1ë‹¨ê³„: ì •ê·œí™” ìƒí’ˆ ì¡°íšŒ
    logger.info("\n1ï¸âƒ£ ì •ê·œí™” ìƒí’ˆ ì¡°íšŒ ì¤‘...")
    
    supplier_id = "e458e4e2-cb03-4fc2-bff1-b05aaffde00f"  # ì˜¤ë„ˆí´ëžœ
    
    query_conditions = {"supplier_id": supplier_id}
    
    if categories:
        logger.info(f"   ì¹´í…Œê³ ë¦¬ í•„í„°: {categories}")
    
    products = await db.select_data(
        "normalized_products",
        query_conditions,
        limit=limit
    )
    
    logger.info(f"   ì •ê·œí™” ìƒí’ˆ: {len(products):,}ê°œ")
    
    # 2ë‹¨ê³„: ìƒí’ˆë³„ ê²€ìƒ‰ í‚¤ì›Œë“œ ìƒì„±
    logger.info("\n2ï¸âƒ£ ê²€ìƒ‰ í‚¤ì›Œë“œ ìƒì„± ì¤‘...")
    
    keyword_product_map = {}  # í‚¤ì›Œë“œ -> ìƒí’ˆ ëª©ë¡ ë§¤í•‘
    
    for product in products:
        try:
            # ìƒí’ˆëª…ì—ì„œ ê²€ìƒ‰ í‚¤ì›Œë“œ ìƒì„± (ë¸Œëžœë“œëª… ì œê±°, ëª¨ë¸ëª… ì¶”ì¶œ)
            title = product.get('title', '')
            category = product.get('category', '')
            
            # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì¶”ì¶œ (ì²« 3-4ë‹¨ì–´)
            keywords = title.split()[:4]
            keyword = ' '.join(keywords)
            
            if not keyword:
                continue
            
            if keyword not in keyword_product_map:
                keyword_product_map[keyword] = []
            
            keyword_product_map[keyword].append({
                'id': product['id'],
                'title': title,
                'price': product.get('price', 0),
                'category': category
            })
            
        except Exception as e:
            logger.warning(f"   í‚¤ì›Œë“œ ìƒì„± ì‹¤íŒ¨: {e}")
            continue
    
    # ì¤‘ë³µ í‚¤ì›Œë“œ ì œê±° ë° ìƒìœ„ Nê°œë§Œ ì„ íƒ (ë„ˆë¬´ ë§Žìœ¼ë©´ API ì œí•œ)
    unique_keywords = list(keyword_product_map.keys())[:500]  # ìƒìœ„ 500ê°œë§Œ
    
    logger.info(f"   ê³ ìœ  í‚¤ì›Œë“œ: {len(unique_keywords):,}ê°œ (ì´ {len(keyword_product_map)}ê°œ ì¤‘)")
    logger.info(f"   ë§¤í•‘ëœ ìƒí’ˆ: {sum(len(v) for v in keyword_product_map.values()):,}ê°œ")
    
    # 3ë‹¨ê³„: ë§ˆì¼“í”Œë ˆì´ìŠ¤ë³„ ê²½ìŸì‚¬ ë°ì´í„° ìˆ˜ì§‘
    logger.info(f"\n3ï¸âƒ£ ê²½ìŸì‚¬ ë°ì´í„° ìˆ˜ì§‘ ì‹œìž‘...")
    logger.info(f"   í”Œëž«í¼: ì¿ íŒ¡, ë„¤ì´ë²„ ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´")
    logger.info(f"   ë°°ì¹˜ í¬ê¸°: {batch_size}ê°œ")
    
    total_collected = {
        'coupang': 0,
        'naver': 0
    }
    
    batch_num = 0
    total_batches = (len(unique_keywords) + batch_size - 1) // batch_size
    
    for i in range(0, len(unique_keywords), batch_size):
        batch_keywords = unique_keywords[i:i + batch_size]
        batch_num += 1
        
        logger.info(f"\n   ë°°ì¹˜ {batch_num}/{total_batches} ìˆ˜ì§‘ ì¤‘... ({len(batch_keywords)}ê°œ í‚¤ì›Œë“œ)")
        
        for idx, keyword in enumerate(batch_keywords, 1):
            try:
                # ì¿ íŒ¡ ê²€ìƒ‰
                try:
                    coupang_products = await coupang_service.search_products(
                        keyword=keyword,
                        page=1
                    )
                    
                    # ìƒìœ„ 10ê°œë§Œ ì‚¬ìš©
                    if coupang_products:
                        coupang_products = coupang_products[:10]
                        saved = await coupang_service.save_competitor_products(
                            coupang_products,
                            keyword
                        )
                        total_collected['coupang'] += saved
                        
                except Exception as e:
                    logger.debug(f"      ì¿ íŒ¡ ê²€ìƒ‰ ì‹¤íŒ¨: {keyword[:30]}, {e}")
                
                # ë„¤ì´ë²„ ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ ê²€ìƒ‰
                try:
                    naver_products = await naver_service.search_products(
                        keyword=keyword,
                        page=1
                    )
                    
                    # ìƒìœ„ 10ê°œë§Œ ì‚¬ìš©
                    if naver_products:
                        naver_products = naver_products[:10]
                        saved = await naver_service.save_competitor_products(
                            naver_products,
                            keyword
                        )
                        total_collected['naver'] += saved
                        
                except Exception as e:
                    logger.debug(f"      ë„¤ì´ë²„ ê²€ìƒ‰ ì‹¤íŒ¨: {keyword[:30]}, {e}")
                
                # ì§„í–‰ë¥  í‘œì‹œ (10ê°œë§ˆë‹¤)
                if idx % 10 == 0:
                    progress = ((i + idx) / len(unique_keywords)) * 100
                    logger.info(f"      ì§„í–‰: {idx}/{len(batch_keywords)} (ì „ì²´: {progress:.1f}%)")
                
                # API í˜¸ì¶œ ê°„ê²© (ê³¼ë¶€í•˜ ë°©ì§€)
                await asyncio.sleep(0.5)
                
            except Exception as e:
                logger.warning(f"      í‚¤ì›Œë“œ ì²˜ë¦¬ ì‹¤íŒ¨: {keyword[:30]}, {e}")
                continue
        
        # ë°°ì¹˜ ì™„ë£Œ
        batch_progress = (batch_num / total_batches) * 100
        logger.info(f"   ë°°ì¹˜ {batch_num} ì™„ë£Œ (ì§„í–‰ë¥ : {batch_progress:.1f}%)")
        logger.info(f"      ëˆ„ì  - ì¿ íŒ¡: {total_collected['coupang']:,}ê°œ, ë„¤ì´ë²„: {total_collected['naver']:,}ê°œ")
        
        # ë°°ì¹˜ ê°„ íœ´ì‹
        await asyncio.sleep(1)
    
    total_time = (datetime.now() - start_time).total_seconds()
    
    logger.info(f"\n{'='*70}")
    logger.info("âœ… ëŒ€ëŸ‰ ê²½ìŸì‚¬ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ!")
    logger.info(f"{'='*70}")
    logger.info(f"   ì²˜ë¦¬ í‚¤ì›Œë“œ: {len(unique_keywords):,}ê°œ")
    logger.info(f"   ì¿ íŒ¡ ìˆ˜ì§‘: {total_collected['coupang']:,}ê°œ")
    logger.info(f"   ë„¤ì´ë²„ ìˆ˜ì§‘: {total_collected['naver']:,}ê°œ")
    logger.info(f"   ì´ ìˆ˜ì§‘: {sum(total_collected.values()):,}ê°œ")
    logger.info(f"   ì´ ì‹œê°„: {total_time/60:.2f}ë¶„")
    logger.info(f"{'='*70}")
    
    result = {
        "status": "success",
        "keywords_processed": len(unique_keywords),
        "coupang_collected": total_collected['coupang'],
        "naver_collected": total_collected['naver'],
        "total_collected": sum(total_collected.values()),
        "total_time": total_time
    }
    
    with open('competitor_data_collection_result.json', 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=2, default=str)
    
    logger.info("ðŸ’¾ ê²°ê³¼ê°€ competitor_data_collection_result.jsonì— ì €ìž¥ë˜ì—ˆìŠµë‹ˆë‹¤")
    
    return result


if __name__ == "__main__":
    import sys
    
    # ëª…ë ¹ì¤„ ì¸ìžë¡œ ì œí•œ ê°€ëŠ¥
    limit = int(sys.argv[1]) if len(sys.argv) > 1 else 1000  # ê¸°ë³¸ 1000ê°œ
    
    result = asyncio.run(bulk_collect_competitor_data(
        limit=limit,
        batch_size=50  # 50ê°œ í‚¤ì›Œë“œì”© ë°°ì¹˜ ì²˜ë¦¬
    ))

