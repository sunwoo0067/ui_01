#!/usr/bin/env python3
"""
ë°°ì¹˜ íƒ€ì… ëŒ€ëŸ‰ ìˆ˜ì§‘ ìŠ¤í¬ë¦½íŠ¸
ë“œë¡­ì‰¬í•‘ ëŒ€ëŸ‰ë“±ë¡ì„ ìœ„í•œ ì „ì²´ ì¹´íƒˆë¡œê·¸ ìˆ˜ì§‘
"""

import asyncio
import json
import hashlib
from datetime import datetime
from typing import List, Dict, Any
from loguru import logger

from src.services.ownerclan_data_collector import OwnerClanDataCollector
from src.services.domaemae_data_collector import DomaemaeDataCollector
from src.services.database_service import DatabaseService


class BatchTypeCollector:
    """ë°°ì¹˜ íƒ€ì… ìˆ˜ì§‘ê¸°"""
    
    def __init__(self):
        self.db = DatabaseService()
        self.ownerclan_collector = OwnerClanDataCollector()
        self.domaemae_collector = DomaemaeDataCollector(self.db)
        
        self.supplier_ids = {
            "ownerclan": "e458e4e2-cb03-4fc2-bff1-b05aaffde00f",
            "domaemae_dome": "d9e6fa42-9bd4-438f-bf3b-10cf199eabd2",
            "domaemae_supply": "a9990a09-ae6f-474b-87b8-75840a110519"
        }
        
        self.results = {}
    
    async def _save_batch_products(self, products: List[Dict], supplier_code: str) -> Dict[str, int]:
        """ë°°ì¹˜ ìƒí’ˆ ë°ì´í„° ì €ì¥"""
        try:
            supplier_id = self.supplier_ids[supplier_code]
            
            saved = 0
            new = 0
            updated = 0
            
            logger.info(f"ğŸ’¾ {supplier_code} ë°°ì¹˜ ì €ì¥ ì‹œì‘: {len(products)}ê°œ")
            
            for idx, product in enumerate(products, 1):
                try:
                    supplier_product_id = product.get("supplier_key", 
                                                     product.get("id", 
                                                                str(product.get("product_id", ""))))
                    
                    data_str = json.dumps(product, sort_keys=True, ensure_ascii=False)
                    data_hash = hashlib.md5(data_str.encode('utf-8')).hexdigest()
                    
                    raw_data = {
                        "supplier_id": supplier_id,
                        "raw_data": json.dumps(product, ensure_ascii=False),
                        "collection_method": "api",
                        "collection_source": "batch_collection",
                        "supplier_product_id": supplier_product_id,
                        "is_processed": False,
                        "data_hash": data_hash,
                        "metadata": json.dumps({
                            "collected_at": product.get("collected_at", datetime.now().isoformat()),
                            "collection_type": "batch"
                        }, ensure_ascii=False)
                    }
                    
                    existing = await self.db.select_data(
                        "raw_product_data",
                        {"supplier_id": supplier_id, "supplier_product_id": supplier_product_id}
                    )
                    
                    if existing:
                        await self.db.update_data("raw_product_data", raw_data, {"id": existing[0]["id"]})
                        updated += 1
                    else:
                        await self.db.insert_data("raw_product_data", raw_data)
                        new += 1
                    
                    saved += 1
                    
                    if idx % 500 == 0:
                        logger.info(f"   ì§„í–‰: {idx}/{len(products)}ê°œ (ì‹ ê·œ: {new}, ì—…ë°ì´íŠ¸: {updated})")
                        
                except Exception as e:
                    logger.warning(f"ì €ì¥ ì‹¤íŒ¨: {e}")
                    continue
            
            logger.info(f"âœ… {supplier_code} ë°°ì¹˜ ì €ì¥ ì™„ë£Œ: {saved}ê°œ")
            
            return {"saved": saved, "new": new, "updated": updated}
            
        except Exception as e:
            logger.error(f"âŒ ë°°ì¹˜ ì €ì¥ ì‹¤íŒ¨: {e}")
            return {"saved": 0, "new": 0, "updated": 0}
    
    async def collect_ownerclan_batch(self):
        """ì˜¤ë„ˆí´ëœ ë°°ì¹˜ íƒ€ì… ìˆ˜ì§‘ (allItems GraphQL)"""
        logger.info("="*70)
        logger.info("ğŸ¢ ì˜¤ë„ˆí´ëœ ë°°ì¹˜ íƒ€ì… ìˆ˜ì§‘ ì‹œì‘")
        logger.info("   ë°©ì‹: allItems GraphQL ì¿¼ë¦¬ (ì „ì²´ ìƒí’ˆ)")
        logger.info("="*70)
        
        try:
            account_name = "test_account"
            start_time = datetime.now()
            
            # GraphQL allItems ì¿¼ë¦¬ë¡œ ì „ì²´ ìƒí’ˆ ìˆ˜ì§‘
            query = """
            query {
                allItems {
                    edges {
                        node {
                            key
                            name
                            model
                            categoryName
                            categoryKey
                            quantity
                            deleted
                            createdAt
                            updatedAt
                            options {
                                key
                                price
                                quantity
                                barcode
                                skuBarcode
                                optionAttributes {
                                    name
                                    value
                                }
                            }
                            itemImages {
                                url
                            }
                        }
                    }
                }
            }
            """
            
            logger.info("ğŸ“¦ allItems GraphQL ì¿¼ë¦¬ ì‹¤í–‰ ì¤‘...")
            
            result = await self.ownerclan_collector._make_graphql_request(query, account_name)
            
            if not result or "data" not in result:
                logger.error("âŒ GraphQL ì¿¼ë¦¬ ì‹¤íŒ¨")
                return {"status": "error", "message": "GraphQL query failed"}
            
            edges = result["data"]["allItems"]["edges"]
            
            logger.info(f"âœ… GraphQL ì‘ë‹µ ìˆ˜ì‹ : {len(edges)}ê°œ ìƒí’ˆ")
            
            # ìƒí’ˆ ë°ì´í„° ë³€í™˜
            all_products = []
            for edge in edges:
                node = edge["node"]
                
                # ì‚­ì œëœ ìƒí’ˆ ì œì™¸
                if node.get("deleted"):
                    continue
                
                product = {
                    "supplier_key": node["key"],
                    "name": node.get("name", ""),
                    "model": node.get("model", ""),
                    "category_name": node.get("categoryName", ""),
                    "category_key": node.get("categoryKey", ""),
                    "quantity": node.get("quantity", 0),
                    "options": node.get("options", []),
                    "images": [img.get("url") for img in node.get("itemImages", [])],
                    "created_at": node.get("createdAt", ""),
                    "updated_at": node.get("updatedAt", ""),
                    "collected_at": datetime.now().isoformat(),
                    "account_name": account_name
                }
                
                # ê°€ê²© ì •ë³´ (ì²« ë²ˆì§¸ ì˜µì…˜ì—ì„œ ì¶”ì¶œ)
                if product["options"]:
                    product["price"] = product["options"][0].get("price", 0)
                
                all_products.append(product)
            
            collection_time = (datetime.now() - start_time).total_seconds()
            
            logger.info(f"âœ… ìƒí’ˆ ë³€í™˜ ì™„ë£Œ: {len(all_products)}ê°œ (ì‚­ì œëœ ìƒí’ˆ ì œì™¸)")
            logger.info(f"   ìˆ˜ì§‘ ì‹œê°„: {collection_time:.2f}ì´ˆ")
            
            # ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥
            save_result = await self._save_batch_products(all_products, "ownerclan")
            
            total_time = (datetime.now() - start_time).total_seconds()
            
            result = {
                "status": "success",
                "total_from_api": len(edges),
                "active_products": len(all_products),
                "new": save_result["new"],
                "updated": save_result["updated"],
                "collection_time": collection_time,
                "total_time": total_time
            }
            
            self.results["ownerclan"] = result
            
            logger.info(f"âœ… ì˜¤ë„ˆí´ëœ ë°°ì¹˜ íƒ€ì… ìˆ˜ì§‘ ì™„ë£Œ!")
            logger.info(f"   API ì‘ë‹µ: {len(edges)}ê°œ")
            logger.info(f"   í™œì„± ìƒí’ˆ: {len(all_products)}ê°œ")
            logger.info(f"   ì‹ ê·œ: {save_result['new']}ê°œ")
            logger.info(f"   ì—…ë°ì´íŠ¸: {save_result['updated']}ê°œ")
            logger.info(f"   ì´ ì‹œê°„: {total_time:.2f}ì´ˆ")
            
            return result
            
        except Exception as e:
            logger.error(f"âŒ ì˜¤ë„ˆí´ëœ ë°°ì¹˜ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            self.results["ownerclan"] = {"status": "error", "error": str(e)}
            return {"status": "error", "error": str(e)}
    
    async def collect_domaemae_batch(self, market: str = "dome"):
        """ë„ë§¤ê¾¹/ë„ë§¤ë§¤ ë°°ì¹˜ íƒ€ì… ìˆ˜ì§‘ (ì „ì²´ ìƒí’ˆ)"""
        market_name = "ë„ë§¤ê¾¹" if market == "dome" else "ë„ë§¤ë§¤"
        supplier_code = f"domaemae_{market}"
        
        logger.info("="*70)
        logger.info(f"ğŸ¢ {market_name} ë°°ì¹˜ íƒ€ì… ìˆ˜ì§‘ ì‹œì‘")
        logger.info(f"   ë°©ì‹: ì „ì²´ í˜ì´ì§€ ìˆœíšŒ (ëŒ€ëŸ‰ ìˆ˜ì§‘)")
        logger.info("="*70)
        
        try:
            account_name = "test_account"
            start_time = datetime.now()
            
            # ì „ì²´ ìƒí’ˆ ìˆ˜ì§‘ (ëª¨ë“  í˜ì´ì§€)
            all_products = []
            page = 1
            page_size = 200
            max_products = 50000  # ìµœëŒ€ 5ë§Œê°œ (ì•ˆì „ì¥ì¹˜)
            
            logger.info(f"ğŸ“¦ {market_name} ì „ì²´ ìƒí’ˆ ë°°ì¹˜ ìˆ˜ì§‘ ì‹œì‘...")
            
            while len(all_products) < max_products:
                logger.info(f"   í˜ì´ì§€ {page} ìˆ˜ì§‘ ì¤‘... (ëˆ„ì : {len(all_products)}ê°œ)")
                
                products = await self.domaemae_collector.collect_products(
                    account_name=account_name,
                    market=market,
                    size=page_size,
                    page=page
                )
                
                if not products:
                    logger.info(f"   ë§ˆì§€ë§‰ í˜ì´ì§€ ë„ë‹¬ (í˜ì´ì§€ {page})")
                    break
                
                all_products.extend(products)
                page += 1
                
                # API Rate Limiting
                await asyncio.sleep(1)
                
                # ì•ˆì „ì¥ì¹˜: ë„ˆë¬´ ë§ì€ í˜ì´ì§€ëŠ” ë°©ì§€
                if page > 250:  # 250í˜ì´ì§€ = 50,000ê°œ
                    logger.warning("ìµœëŒ€ í˜ì´ì§€ ë„ë‹¬")
                    break
            
            collection_time = (datetime.now() - start_time).total_seconds()
            
            logger.info(f"âœ… {market_name} ë°°ì¹˜ ìˆ˜ì§‘ ì™„ë£Œ: {len(all_products)}ê°œ")
            logger.info(f"   ìˆ˜ì§‘ ì‹œê°„: {collection_time:.2f}ì´ˆ")
            logger.info(f"   ìˆ˜ì§‘ ì†ë„: {len(all_products)/collection_time:.2f}ê°œ/ì´ˆ")
            
            if not all_products:
                return {"status": "no_data"}
            
            # ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥
            save_result = await self._save_batch_products(all_products, supplier_code)
            
            total_time = (datetime.now() - start_time).total_seconds()
            
            result = {
                "status": "success",
                "collected": len(all_products),
                "new": save_result["new"],
                "updated": save_result["updated"],
                "pages": page - 1,
                "collection_time": collection_time,
                "total_time": total_time
            }
            
            self.results[supplier_code] = result
            
            logger.info(f"âœ… {market_name} ë°°ì¹˜ íƒ€ì… ìˆ˜ì§‘ ì™„ë£Œ!")
            logger.info(f"   ìˆ˜ì§‘: {len(all_products)}ê°œ")
            logger.info(f"   í˜ì´ì§€: {page-1}ê°œ")
            logger.info(f"   ì‹ ê·œ: {save_result['new']}ê°œ")
            logger.info(f"   ì—…ë°ì´íŠ¸: {save_result['updated']}ê°œ")
            logger.info(f"   ì´ ì‹œê°„: {total_time:.2f}ì´ˆ")
            
            return result
            
        except Exception as e:
            logger.error(f"âŒ {market_name} ë°°ì¹˜ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            self.results[supplier_code] = {"status": "error", "error": str(e)}
            return {"status": "error", "error": str(e)}
    
    async def run_all_batch_collections(self):
        """ëª¨ë“  ë°°ì¹˜ íƒ€ì… ìˆ˜ì§‘ ì‹¤í–‰"""
        logger.info("ğŸš€ ë°°ì¹˜ íƒ€ì… ëŒ€ëŸ‰ ìˆ˜ì§‘ ì‹œì‘")
        logger.info("   ëª©í‘œ: ë“œë¡­ì‰¬í•‘ ëŒ€ëŸ‰ë“±ë¡ì„ ìœ„í•œ ì „ì²´ ì¹´íƒˆë¡œê·¸ ìˆ˜ì§‘")
        logger.info("="*70)
        
        start_time = datetime.now()
        
        # 1. ì˜¤ë„ˆí´ëœ ë°°ì¹˜ ìˆ˜ì§‘
        await self.collect_ownerclan_batch()
        
        # 2. ë„ë§¤ê¾¹(dome) ë°°ì¹˜ ìˆ˜ì§‘
        await self.collect_domaemae_batch(market="dome")
        
        # 3. ë„ë§¤ë§¤(supply) ë°°ì¹˜ ìˆ˜ì§‘
        await self.collect_domaemae_batch(market="supply")
        
        total_time = (datetime.now() - start_time).total_seconds()
        
        # ê²°ê³¼ ìš”ì•½
        logger.info("\n" + "="*70)
        logger.info("ğŸ“Š ë°°ì¹˜ íƒ€ì… ìˆ˜ì§‘ ê²°ê³¼ ìš”ì•½")
        logger.info("="*70)
        
        total_collected = 0
        total_new = 0
        total_updated = 0
        
        for supplier, result in self.results.items():
            logger.info(f"\nğŸ¢ {supplier}:")
            if result.get("status") == "success":
                logger.info(f"   âœ… ìˆ˜ì§‘: {result.get('collected', 0)}ê°œ")
                logger.info(f"   ğŸ“ ì‹ ê·œ: {result.get('new', 0)}ê°œ")
                logger.info(f"   ğŸ”„ ì—…ë°ì´íŠ¸: {result.get('updated', 0)}ê°œ")
                total_collected += result.get('collected', 0)
                total_new += result.get('new', 0)
                total_updated += result.get('updated', 0)
            else:
                logger.info(f"   âŒ ì‹¤íŒ¨: {result.get('error', 'Unknown')}")
        
        logger.info(f"\n{'='*70}")
        logger.info(f"ì´ ìˆ˜ì§‘: {total_collected}ê°œ")
        logger.info(f"ì‹ ê·œ ì €ì¥: {total_new}ê°œ")
        logger.info(f"ì—…ë°ì´íŠ¸: {total_updated}ê°œ")
        logger.info(f"ì´ ì†Œìš” ì‹œê°„: {total_time/60:.2f}ë¶„")
        logger.info("="*70)
        
        self.results["summary"] = {
            "total_collected": total_collected,
            "total_new": total_new,
            "total_updated": total_updated,
            "total_time": total_time,
            "timestamp": datetime.now().isoformat()
        }
        
        return self.results


async def main():
    """ë©”ì¸ ì‹¤í–‰"""
    collector = BatchTypeCollector()
    results = await collector.run_all_batch_collections()
    
    # ê²°ê³¼ ì €ì¥
    with open('batch_type_collection_results.json', 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2, default=str)
    
    logger.info("\nğŸ’¾ ê²°ê³¼ê°€ batch_type_collection_results.jsonì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤")


if __name__ == "__main__":
    asyncio.run(main())

